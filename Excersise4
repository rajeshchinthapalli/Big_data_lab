hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ cd $HADOOP_HOME
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1$ cd sbin
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ start-all.sh
WARNING: Attempting to start all Apache Hadoop daemons as hdoop in 10 seconds.
WARNING: This is not a recommended production deployment configuration.
WARNING: Use CTRL-C to abort.
Starting namenodes on [localhost]
localhost: namenode is running as process 5154.  Stop it first.
Starting datanodes
localhost: datanode is running as process 5297.  Stop it first.
Starting secondary namenodes [admin1-HP-280-G4-MT-Business-PC]
admin1-HP-280-G4-MT-Business-PC: secondarynamenode is running as process 5538.  Stop it first.
Starting resourcemanager
resourcemanager is running as process 5726.  Stop it first.
Starting nodemanagers
localhost: nodemanager is running as process 5876.  Stop it first.
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ jps
5297 DataNode
5538 SecondaryNameNode
5154 NameNode
5876 NodeManager
20314 Jps
5726 ResourceManager
18846 org.eclipse.equinox.launcher_1.5.600.v20191014-2022.jar
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ hdfs dfs -mkdir -p  /input155
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ hdfs dfs -copyFromLocal /home/hdoop/myfile11/bank_data.csv /input101
copyFromLocal: `/home/hdoop/myfile11/bank_data.csv': No such file or directory
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ hdfs dfs -copyFromLocal /home/hdoop/myfiles11/bank_data.csv /input101
2022-06-21 10:37:05,276 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ hadoop jar /home/hdoop/Desktop/Rajesh.jar /input101 /output101
2022-06-21 10:38:42,851 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032
2022-06-21 10:38:42,972 INFO client.RMProxy: Connecting to ResourceManager at /127.0.0.1:8032
2022-06-21 10:38:43,098 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2022-06-21 10:38:43,132 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/hdoop/.staging/job_1655782542459_0002
2022-06-21 10:38:43,231 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2022-06-21 10:38:43,346 INFO mapred.FileInputFormat: Total input files to process : 1
2022-06-21 10:38:43,398 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2022-06-21 10:38:43,449 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2022-06-21 10:38:43,466 INFO mapreduce.JobSubmitter: number of splits:2
2022-06-21 10:38:43,581 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2022-06-21 10:38:43,589 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1655782542459_0002
2022-06-21 10:38:43,590 INFO mapreduce.JobSubmitter: Executing with tokens: []
2022-06-21 10:38:43,699 INFO conf.Configuration: resource-types.xml not found
2022-06-21 10:38:43,700 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2022-06-21 10:38:43,742 INFO impl.YarnClientImpl: Submitted application application_1655782542459_0002
2022-06-21 10:38:43,766 INFO mapreduce.Job: The url to track the job: http://admin1-HP-280-G4-MT-Business-PC:8088/proxy/application_1655782542459_0002/
2022-06-21 10:38:43,767 INFO mapreduce.Job: Running job: job_1655782542459_0002
2022-06-21 10:38:47,878 INFO mapreduce.Job: Job job_1655782542459_0002 running in uber mode : false
2022-06-21 10:38:47,880 INFO mapreduce.Job:  map 0% reduce 0%
2022-06-21 10:38:51,966 INFO mapreduce.Job:  map 100% reduce 0%
2022-06-21 10:38:55,993 INFO mapreduce.Job:  map 100% reduce 100%
2022-06-21 10:38:56,002 INFO mapreduce.Job: Job job_1655782542459_0002 completed successfully
2022-06-21 10:38:56,056 INFO mapreduce.Job: Counters: 55
	File System Counters
		FILE: Number of bytes read=63
		FILE: Number of bytes written=677582
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=334
		HDFS: Number of bytes written=30
		HDFS: Number of read operations=11
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters 
		Killed map tasks=1
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=2
		Total time spent by all maps in occupied slots (ms)=3502
		Total time spent by all reduces in occupied slots (ms)=1429
		Total time spent by all map tasks (ms)=3502
		Total time spent by all reduce tasks (ms)=1429
		Total vcore-milliseconds taken by all map tasks=3502
		Total vcore-milliseconds taken by all reduce tasks=1429
		Total megabyte-milliseconds taken by all map tasks=3586048
		Total megabyte-milliseconds taken by all reduce tasks=1463296
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=47
		Map output materialized bytes=69
		Input split bytes=164
		Combine input records=5
		Combine output records=5
		Reduce input groups=4
		Reduce shuffle bytes=69
		Reduce input records=5
		Reduce output records=4
		Spilled Records=10
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=159
		CPU time spent (ms)=1070
		Physical memory (bytes) snapshot=821903360
		Virtual memory (bytes) snapshot=7608852480
		Total committed heap usage (bytes)=852492288
		Peak Map Physical memory (bytes)=335699968
		Peak Map Virtual memory (bytes)=2534510592
		Peak Reduce Physical memory (bytes)=191754240
		Peak Reduce Virtual memory (bytes)=2544381952
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=170
	File Output Format Counters 
		Bytes Written=30
hdoop@admin1-HP-280-G4-MT-Business-PC:~/hadoop-3.2.1/sbin$ hdfs dfs -cat /output101/part*

2022-06-21 10:39:16,762 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
1200	2
1500	1
1700	1
Amount	1
